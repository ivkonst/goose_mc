{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of Notes from Downloaded Sites\n",
    "1. Form lists of phrases for each text\n",
    "2. Repair words with star (ex.: ж*па -> жопа)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import jsonlines\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_dir = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_soup(dd, link):\n",
    "    print('\\n'.join([abstract[0] for abstract in dd[link] if abstract[1] == 'text']))\n",
    "    \n",
    "def look_listphrases(listphrases):\n",
    "    print('\\n***********\\n'.join(['\\n'.join(paragraph) for paragraph in listphrases]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prohiphop.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "131it [00:00, 4429.90it/s]\n"
     ]
    }
   ],
   "source": [
    "dd_prohiphop = defaultdict(list)\n",
    "\n",
    "with jsonlines.open(os.path.join(data_dir,'site_soup_prohiphop.jsonl')) as fd:\n",
    "    for obj in tqdm(fd):\n",
    "        dd_prohiphop[obj['link']] += obj['soup']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "texts didn't download :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### webrap.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3152it [00:00, 5601.72it/s]\n"
     ]
    }
   ],
   "source": [
    "dd_webrap = defaultdict(list)\n",
    "\n",
    "with jsonlines.open(os.path.join(data_dir,'site_soup_webrap.jsonl')) as fd:\n",
    "    for obj in tqdm(fd):\n",
    "        dd_webrap[obj['link']] += obj['soup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n"
     ]
    }
   ],
   "source": [
    "list_text_uchastnikov_versusa = sorted([link for link in dd_webrap if re.match('^\\S*/text-uchastnikov-versusa\\S+$', link) != None])\n",
    "print(len(list_text_uchastnikov_versusa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1725\n"
     ]
    }
   ],
   "source": [
    "list_text_pesen = sorted([link for link in dd_webrap if re.match('^\\S*/text-pesen\\S+/\\S+$', link) != None])\n",
    "print(len(list_text_pesen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(soup):\n",
    "    list_text = []\n",
    "    list_tmp = []\n",
    "    fl_israp = 0\n",
    "    fl_newparagraph = 0\n",
    "    for abstract in soup:\n",
    "        fl_isphrase = 1\n",
    "        text = abstract[0]\n",
    "        block = abstract[2]\n",
    "        if re.match('^Просмотров: \\d+$', text) != None:\n",
    "            fl_israp = 1\n",
    "            fl_isphrase = 0\n",
    "        elif (fl_israp == 1) and ('a:' in block) and (len(list_text) > 0):\n",
    "            fl_israp = 0\n",
    "            fl_isphrase = 0\n",
    "        elif re.match('^\\S*h\\d:\\S*$', block) != None:\n",
    "            fl_isphrase = 0\n",
    "            fl_newparagraph = 1\n",
    "            \n",
    "        if (fl_israp == 1) and (fl_isphrase == 1):\n",
    "            if fl_newparagraph == 1:\n",
    "                if len(list_tmp) > 0:\n",
    "                    list_text.append(list_tmp)\n",
    "                    list_tmp = [text]\n",
    "                else:\n",
    "                    list_tmp = [text]\n",
    "                fl_newparagraph = 0\n",
    "            else:\n",
    "                list_tmp.append(text)\n",
    "    if len(list_tmp) > 0:\n",
    "        list_text.append(list_tmp)\n",
    "    return list_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 247/247 [00:00<00:00, 1512.97it/s]\n"
     ]
    }
   ],
   "source": [
    "dd_text_uchastnikov_versusa = {link:extraction(dd_webrap[link]) for link in tqdm(list_text_uchastnikov_versusa)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(soup):\n",
    "    list_text = []\n",
    "    list_tmp = []\n",
    "    fl_israp = 0\n",
    "    fl_newparagraph = 0\n",
    "    num_paragraph = -999\n",
    "    for abstract in soup:\n",
    "        fl_isphrase = 1\n",
    "        text = abstract[0]\n",
    "        block = abstract[2]\n",
    "        if re.match('^Просмотров: \\d+$', text) != None:\n",
    "            fl_israp = 1\n",
    "            fl_isphrase = 0\n",
    "        elif 'a:' in block:\n",
    "            fl_israp = 0\n",
    "            fl_isphrase = 0\n",
    "        elif ('припев' in text.lower()) and (len(text) <= 20):\n",
    "            fl_isphrase = 0\n",
    "            \n",
    "        if re.match('^\\S*p:\\S*$', block) != None:\n",
    "            num_paragraph_curr = int(re.findall(r'p:\\d+', block)[0].split(':')[1])\n",
    "            if num_paragraph_curr > num_paragraph:\n",
    "                num_paragraph = num_paragraph_curr\n",
    "                fl_newparagraph = 1\n",
    "        \n",
    "        if (fl_israp == 1) and (fl_isphrase == 1):\n",
    "            if fl_newparagraph == 1:\n",
    "                if len(list_tmp) > 0:\n",
    "                    list_text.append(list_tmp)\n",
    "                    list_tmp = [text]\n",
    "                else:\n",
    "                    list_tmp = [text]\n",
    "                fl_newparagraph = 0\n",
    "            else:\n",
    "                list_tmp.append(text)\n",
    "    if len(list_tmp) > 0:\n",
    "        list_text.append(list_tmp)\n",
    "    \n",
    "    if len(list_text) >= 10:\n",
    "        list_text = [[phrase for paragraph in list_text for phrase in paragraph]]\n",
    "    \n",
    "    return list_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1725/1725 [00:00<00:00, 2062.57it/s]\n"
     ]
    }
   ],
   "source": [
    "dd_text_pesen = {link:extraction(dd_webrap[link]) for link in tqdm(list_text_pesen)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1972\n"
     ]
    }
   ],
   "source": [
    "dd_webrap_texts = dd_text_uchastnikov_versusa.copy()\n",
    "\n",
    "for link, list_text in dd_text_pesen.items():\n",
    "    dd_webrap_texts[link] = list_text\n",
    "print(len(dd_webrap_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open(os.path.join(data_dir, 'texts_webrap.jsonl'), mode='w') as fd:\n",
    "    for link, list_texts in dd_webrap_texts.items():\n",
    "        if len(list_texts) > 0:\n",
    "            fd.write({'link':link, 'list_texts':list_texts})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rap-text.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
